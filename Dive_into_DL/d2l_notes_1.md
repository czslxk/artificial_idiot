# 动手学深度学习 学习记录（一）

## 线性回归
问题：给定数据集 $X \in \mathbb{R}^{n\times m}$，求 $w\in \mathbb{R}^m, b\in \mathbb{R}$ 使得 $\Vert Xw+b1 \Vert$ 最小。

解决方法：使用小批量随机梯度下降（MSGD）进行优化。

实现的时候本质上使用的都是单层线性网络。

## 单类别分类问题
问题：给定数据集 $X \in \mathbb{R}^{n\times m}$ 和对应的类别标签 $y\in \mathbb{N}^{n}$，希望找到一种方法能正确的对 $X$ 中的数据进行分类。

解决方法：设类别个数为 $q$，将 $y$ 扩展为 One-hot 矩阵 $\left\{0, 1\right\}^{n\times q}$，然后设定参数 $w\in \mathbb{R}^{m\times q}, b\in \mathbb{R}^{q}$，使用输出层的激活函数为 softmax 函数的单层网络进行训练。

对于一个向量 $x\in \mathbb{R}^{q}$，softmax 函数的输出 $\hat{x}$ 满足 $\hat{x}_{i} = \frac{\exp(x_{i})}{\sum_{j=1}^{q} \exp(x_{j})$。

之所以将上述函数称为 softmax 函数，是因为它执行的是类似于 $\max$ 函数的功能，又在其基础上将所有参数映射到 $(0, 1)$ 这个区间（即对原值 soft 了）。

## 多层感知机
即多层神经网络。一般而言遵循：后一层的结果由前一层的结果先后经仿射变换和激活函数变换后得到。

## 文本预处理
最简单的模型：序列模型，即构建单词和自然数的双射，然后将文本转换为序列作为输入。

该方法具有很多缺点，如丢弃了标点符号、无法处理时态、无法处理一些特殊的词等。

## 语言模型：n 元语法
$n$ 元语法对应的是 $n-1$ 阶马尔可夫链，即认为一个词的出现只和前面 $n-1$ 个词相关。

这样就可以将文本按照 $n$ 元组统计，用频率代替概率计算，然后依照条件概率计算一个文本序列 $(w_1, w_2, \cdots, w_t)$ 的概率。

## 循环神经网络
采用类似于递推的方法进行状态更新。